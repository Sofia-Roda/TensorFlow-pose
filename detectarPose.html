<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Pose con BlazePose</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;500;700&display=swap" rel="stylesheet">

<style>
  body {
    font-family: 'Poppins', sans-serif;
    background: linear-gradient(to right, #fce3ec, #ffe6f0);
    margin: 0;
    padding: 20px;
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  video, canvas {
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    margin-bottom: 20px;
  }

  #captura, #captura2 {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    width: 320px;
    height: auto;
    margin: 10px;
  }

  #contador {
    font-size: 60px;
    font-weight: bold;
    color: #ff4d6d;
    margin-bottom: 20px;
    display: none;
  }

  button {
    background-color: #ff6b81;
    border: none;
    color: white;
    padding: 10px 20px;
    margin: 8px;
    border-radius: 8px;
    cursor: pointer;
    font-size: 16px;
    transition: background-color 0.3s ease;
  }

  button:hover {
    background-color: #ff4d6d;
  }

  .capturas {
    display: flex;
    gap: 20px;
    flex-wrap: wrap;
    justify-content: center;
  }

  /* Video con espejo */
  video {
    transform: scaleX(-1); /* Espejo horizontal */
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    width: 640px; /* Ajustamos el tamaño del video */
    height: 480px;
    position: relative; /* Necesario para poner el canvas encima */
  }

  /* Canvas sobre el video */
  canvas {
    transform: scaleX(-1); /* Espejo en el canvas */
    position: absolute;
    top: 0;
    left: 0;
    width: 640px;
    height: 480px;
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
  }
</style>


</head>
<body>
    <div id="contador"></div>
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="canvas" width="640" height="480" style="display: none;"></canvas>
    
    <div class="capturas">
      <img id="captura" alt="Captura 1">
      <img id="captura2" alt="Captura 2">
    </div>

    <button id="btnReiniciar" style="display: none;">Reiniciar</button>
    

<button id="btnCapturarOtra" style="display:none;" onclick="capturarOtraImagen()">Capturar de nuevo</button>
<button id="btnReiniciar" style="display:none;" onclick="reiniciarCapturas()">Reiniciar</button>

<script>
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  const img1 = document.getElementById('captura');
  const img2 = document.getElementById('captura2');
  const btnOtra = document.getElementById('btnCapturarOtra');
  const btnReiniciar = document.getElementById('btnReiniciar');

  let detector;

  async function setupCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { width: 640, height: 480 },
      audio: false
    });
    video.srcObject = stream;
    return new Promise(resolve => {
      video.onloadedmetadata = () => resolve(video);
    });
  }

  function drawKeypoints(context, keypoints) {
    keypoints.forEach(({ x, y, score }) => {
      if (score > 0.5) {
        context.beginPath();
        context.arc(x, y, 5, 0, 2 * Math.PI);
        context.fillStyle = 'red';
        context.fill();
      }
    });
  }

  function drawSkeleton(context, keypoints) {
    const adjacentPairs = poseDetection.util.getAdjacentPairs(poseDetection.SupportedModels.BlazePose);
    adjacentPairs.forEach(([i, j]) => {
      const kp1 = keypoints[i];
      const kp2 = keypoints[j];
      if (kp1.score > 0.5 && kp2.score > 0.5) {
        context.beginPath();
        context.moveTo(kp1.x, kp1.y);
        context.lineTo(kp2.x, kp2.y);
        context.lineWidth = 2;
        context.strokeStyle = 'blue';
        context.stroke();
      }
    });
  }

  async function capturarImagen(destino) {
    const tempCanvas = document.createElement('canvas');
    const tempCtx = tempCanvas.getContext('2d');
    tempCanvas.width = video.videoWidth;
    tempCanvas.height = video.videoHeight;

    // Espejo: invertir horizontalmente
    tempCtx.translate(tempCanvas.width, 0);
    tempCtx.scale(-1, 1);
    tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

    const poses = await detector.estimatePoses(video);
    if (poses.length > 0) {
      const keypoints = poses[0].keypoints;
      drawKeypoints(tempCtx, keypoints);
      drawSkeleton(tempCtx, keypoints);
    }

    const dataURL = tempCanvas.toDataURL();
    destino.src = dataURL;
  }
  
  function mostrarCuentaRegresiva(segundos, callback) {
  const contador = document.getElementById('contador');
  contador.style.display = 'block';
  contador.textContent = segundos;

  const intervalo = setInterval(() => {
    segundos--;
    if (segundos > 0) {
      contador.textContent = segundos;
    } else {
      clearInterval(intervalo);
      contador.style.display = 'none';
      callback(); // Ejecuta lo que venga después (ej: capturar imagen)
    }
  }, 1000);
}

  async function capturarImagenInicial() {
    await capturarImagen(img1);
    btnOtra.style.display = 'inline';
  }

  async function capturarOtraImagen() {
    await capturarImagen(img2);
    btnOtra.style.display = 'none';
    btnReiniciar.style.display = 'inline';
  }

  function iniciarCapturaAutomatica() {
  mostrarCuentaRegresiva(5, async () => {
    await capturarImagen(img1);
    mostrarCuentaRegresiva(5, async () => {
      await capturarImagen(img2);
      btnReiniciar.style.display = 'inline';
    });
  });
}

function reiniciarCapturas() {
  img1.src = "";
  img2.src = "";
  btnReiniciar.style.display = "none";
  iniciarCapturaAutomatica(); // Vuelve a empezar con las cuentas regresivas
}

  async function main() {
    await setupCamera();
    video.play();

    const detectorConfig = {
      runtime: 'mediapipe',
      modelType: 'full',
      solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'
    };

    detector = await poseDetection.createDetector(poseDetection.SupportedModels.BlazePose, detectorConfig);

    iniciarCapturaAutomatica();

    async function render() {
  const poses = await detector.estimatePoses(video);
  
  // Limpiar el canvas antes de redibujar
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  // Espejo en el video (ya reflejado por CSS en el video)
  ctx.save();
  ctx.scale(-1, 1);  // Esto refleja el canvas horizontalmente
  ctx.translate(-canvas.width, 0);  // Necesario para que el efecto se vea bien
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  ctx.restore();

  if (poses.length > 0) {
    const keypoints = poses[0].keypoints;

    // Reflejar coordenadas de los puntos
    const mirroredKeypoints = keypoints.map(kp => ({
      ...kp,
      x: canvas.width - kp.x // Invertimos horizontalmente las coordenadas
    }));

    // Dibujar los puntos en el canvas sobre el video
    drawKeypoints(ctx, mirroredKeypoints);
    drawSkeleton(ctx, mirroredKeypoints);
  }

  requestAnimationFrame(render);
}

    render();
  }

  main();
</script>
</body>
</html>
